_target_: src.models.diffusion.LDM
# _partial_: True

defaults:
  - sampler: ddim.yaml
  - vae: ../autoencoder/autoencoder_kl_d8_z4.yaml
  - text_encoder: ../condition_encoder/clip.yaml
  - _self_

num_train_timesteps: 1000
first_stage_key: image
conditional_stage_key: prompt
log_every_t: 10

sampler:
  beta_schedule: cosine

unet:
  _target_: src.models.unet.Unet
  in_channels: 4
  out_channels: 4
  sample_size: [32, 32]
  hidden_channels: [128, 256, 512, 512]
  context_dim: 768
  num_res_blocks: 2
  attn_type: standard
  attention_levels: [0, 1]
  dropout: 0.1
  dim: 2
  num_attn_heads: 8
  channels_per_head: 64
  use_spatial_transformer: true

optimizer:
  _target_: torch.optim.AdamW
  _partial_: True
  lr: 2e-4
  weight_decay: 0.0001

scheduler_config:
  scheduler:
    _target_: torch.optim.lr_scheduler.OneCycleLR
    _partial_: True
    max_lr: 2e-4
    total_steps: ${trainer.max_epochs}
  interval: epoch
